{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import wave\n",
    "from scipy.signal import spectrogram\n",
    "import soundfile as sf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data, samplerate = sf.read(\n",
    "    '/Users/GodSpeed/Documents/Courses/Machine Learning/Project/LibriSpeech/dev-clean/84/121123/84-121123-0004.flac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70400\n",
      "16000\n",
      "No. of sample frequencies:  161\n",
      "No. of time segmnets: 439\n",
      "Spectrogram length:  161\n",
      "(161, 439)\n"
     ]
    }
   ],
   "source": [
    "print len(data)\n",
    "print samplerate\n",
    "#taking 20ms samples\n",
    "fft_length = 0.001 * 20 * samplerate\n",
    "overlap_length = 0.001 * 10 * samplerate\n",
    "#print window_size\n",
    "f, t, Sxx = spectrogram(data, fs = samplerate, nperseg = fft_length, \n",
    "                        noverlap = overlap_length)\n",
    "print \"No. of sample frequencies: \", len(f) #len(signal.spectrogram(data)[0])\n",
    "print \"No. of time segmnets:\", len(t)\n",
    "print \"Spectrogram length: \", len(Sxx)\n",
    "print Sxx.shape\n",
    "#data is in the form [frequencies[time]]\n",
    "#print type(Sxx)\n",
    "#for i in range(len(t) -  1):\n",
    "#    print t[i+1] - t[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(t,f,Sxx)\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.show()\n",
    "#print Sxx[:,313]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_labels = {}\n",
    "for i in range(26):\n",
    "    output_labels[i] = chr(i+97)\n",
    "output_labels[i+1] = ' '\n",
    "output_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize weights\n",
    "Following conventions in SPEECH RECOGNITION WITH DEEP RECURRENT NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set layer sizes\n",
    "layers_sizes = [len(Sxx), 200, len(output_labels)]\n",
    "input_size = len(Sxx)\n",
    "\n",
    "\"\"\"this function is to initialize wi, \n",
    "weights from input layer to first hidden layer,\n",
    "in the form [input layer[hidden layer]]\"\"\"\n",
    "def initialize_wx(layers_sizes):\n",
    "    input_size = layers_sizes[0]\n",
    "    first_hidden_layer_size = layers_sizes[1]\n",
    "    e = np.sqrt(6)/np.sqrt(input_size + first_hidden_layer_size)\n",
    "    wx = np.dot(np.random.rand(input_size, \n",
    "                               first_hidden_layer_size), 2*e) - e\n",
    "    return wx\n",
    "\n",
    "\"\"\"this function is to initialize wh,\n",
    "weights from each hidden layer to next hidden layer\n",
    "creating wh array as [layer number[input layer[output layer]]]\"\"\"\n",
    "def initialize_W_hh_next(layers_sizes):\n",
    "    hidden_layers_sizes = layers_sizes[1:-1]\n",
    "    num_layers = len(hidden_layers_sizes)\n",
    "    #return empty if only one hidden layer\n",
    "    if num_layers == 1:\n",
    "        return\n",
    "    wh = np.zeros((num_layers - 1, max(hidden_layers_sizes),\n",
    "                   max(hidden_layers_sizes[1:len(hidden_layers_sizes)])))\n",
    "    for i in range(num_layers - 1):\n",
    "        e = np.sqrt(6)/np.sqrt(hidden_layers_sizes[i]+hidden_layers_sizes[i+1])\n",
    "        wh[i, 0:hidden_layers_sizes[i], 0:hidden_layers_sizes[i+1]] = np.dot(\n",
    "            np.random.rand((hidden_layers_sizes[i]), hidden_layers_sizes[i+1]),\n",
    "            2*e)-e\n",
    "    return wh\n",
    "\n",
    "\"\"\"this function is to initialize wi, \n",
    "weights from last hidden layer to output layer,\n",
    "in the form [hidden layer[output layer]]\"\"\"\n",
    "def initialize_wo(layers_sizes):\n",
    "    last_hidden_layer_size = layers_sizes[-2]\n",
    "    output_size = layers_sizes[-1]\n",
    "    wo = initialize_wx([layers_sizes[-2],layers_sizes[-1]])\n",
    "    return wo\n",
    "\n",
    "\"\"\"initialize recurrent weights for hidden layer on itself\"\"\"\n",
    "def initialize_wh(layers_sizes):\n",
    "    hidden_layers_sizes = layers_sizes[1:-1]\n",
    "    num_hidden_layers = len(hidden_layers_sizes)\n",
    "    wh = np.zeros((max(hidden_layers_sizes), num_hidden_layers))\n",
    "    #print w_hh_curr.shape\n",
    "    #return\n",
    "    for i in range(num_hidden_layers):\n",
    "        e = np.sqrt(6)/np.sqrt(2*hidden_layers_sizes[0])\n",
    "        wh[0:hidden_layers_sizes[i], i] = np.dot(\n",
    "            np.random.rand(hidden_layers_sizes[i]), 2*e) - e\n",
    "    return wh\n",
    "\n",
    "def initialize_wc(layers_sizes):\n",
    "    wc = initialize_wh(layers_sizes)\n",
    "    return wc\n",
    "\n",
    "\n",
    "#initialize weights from input to 1st hidden layer\n",
    "w_xi = initialize_wx(layers_sizes)\n",
    "\n",
    "#initialize w_hi\n",
    "w_hi = initialize_wh(layers_sizes)\n",
    "\n",
    "#initialize w_ci\n",
    "w_ci = initialize_wc(layers_sizes)\n",
    "\n",
    "#initialize w_xf\n",
    "w_xf = initialize_wx(layers_sizes)\n",
    "\n",
    "#initialize w_hf\n",
    "w_hf = initialize_wh(layers_sizes)\n",
    "\n",
    "#initialize w_cf\n",
    "w_cf = initialize_wc(layers_sizes)\n",
    "\n",
    "#initialize w_xc\n",
    "w_xc = initialize_wx(layers_sizes)\n",
    "\n",
    "#initialize w_hc\n",
    "w_hc = initialize_wh(layers_sizes)\n",
    "\n",
    "#initialize w_xo\n",
    "w_xo = initialize_wx(layers_sizes)\n",
    "\n",
    "#initialize w_ho\n",
    "w_ho = initialize_wh(layers_sizes)\n",
    "\n",
    "#initialize w_co\n",
    "w_co = initialize_wc(layers_sizes)\n",
    "\n",
    "\n",
    "#initialize weights from each hidden layer to next hidden layer\n",
    "wh_next = initialize_W_hh_next(layers_sizes)\n",
    "\n",
    "#initialize weights from last hidden layer to output layer\n",
    "w_hy = initialize_wo(layers_sizes)\n",
    "\n",
    "#initialize recurrent weights to 0\n",
    "#w_hh_curr = initialize_w_hh_curr(layers_sizes)\n",
    "\n",
    "#print w_hi.shape\n",
    "#print w_xi.shape\n",
    "#print wh_next.shape\n",
    "#print w_hy.shape\n",
    "#print w_hh_curr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize h(t-1) and c(t-1) to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 1)\n",
      "(200, 1)\n"
     ]
    }
   ],
   "source": [
    "def initialize_empty_state(layers_sizes):\n",
    "    hidden_layers_sizes = layers_sizes[1:-1]\n",
    "    num_hidden_layers = len(hidden_layers_sizes)\n",
    "    empty_state = np.zeros((max(hidden_layers_sizes), num_hidden_layers))\n",
    "    return empty_state\n",
    "\n",
    "hidden_state_prev = initialize_empty_state(layers_sizes)\n",
    "cell_state_prev = initialize_empty_state(layers_sizes)\n",
    "print hidden_state_prev.shape\n",
    "print cell_state_prev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161, 439)\n",
      "439\n",
      "161\n"
     ]
    }
   ],
   "source": [
    "print Sxx.shape\n",
    "print len(t)\n",
    "print len(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08098789  0.08417584  0.03637687 -0.05497636 -0.06230177]\n"
     ]
    }
   ],
   "source": [
    "e = np.sqrt(6)/np.sqrt(2*layers_sizes[1])\n",
    "print np.dot(np.random.rand(5), 2*e) - e\n",
    "#bias_i, bias_o, bias_f, bias_c, bias_y = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161, 10)\n",
      "[[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "class Model(object):\n",
    "    def sigmoid(z):\n",
    "        \"\"\"z: net input from previous layer\n",
    "        a: sigmoid activation of net input\"\"\"\n",
    "        a = 1.0/(1.0+np.exp(-z))\n",
    "        return a\n",
    "    \n",
    "    def tanh(z):\n",
    "        \"\"\"z: net input from previous layer\n",
    "        a: tanh activation of input\"\"\"\n",
    "        a = (np.exp(-z) - np.exp(-z))/(np.exp(-z) + np.exp(-z))\n",
    "        return a\n",
    "    \n",
    "    def feedforward(mini_batch):\n",
    "        \"\"\"mini_batch: mini batch for training is to be done\n",
    "        return: input_gate: input gate values for the mini batch\n",
    "                forget_gate: forget gate values for the mini batch\n",
    "                cell_state_gate: cell state for the mini batch\n",
    "                output_gate: output gate values for the mini batch\n",
    "                hidden_state: hidden state values for the mini batch\n",
    "                y: output\"\"\"\n",
    "        input_gate = sigmoid(np.dot(np.transpose(w_xi), xi)\n",
    "                             + (w_hi * hidden_state_prev) \n",
    "                             + (w_ci * cell_state_prev) + bias_i)\n",
    "        forget_gate = sigmoid(np.dot(np.transpose(w_xf), xi) + \n",
    "                              (w_hf * hidden_state_prev) + \n",
    "                              (w_cf * cell_state_prev) + bias_f)\n",
    "        cell_state_gate = (forget_gate * cell_state_prev) + (input_gate * tanh(np.dot(\n",
    "                    np.transpose(w_xc), xi) + (w_hc * hidden_state_prev) + bias_c))\n",
    "        output_gate = sigmoid(np.dot(np.transpose(w_xo), xi) \n",
    "                              + (w_ho * hidden_state_prev) \n",
    "                              + (w_co * cell_state_gate) + bias_o)\n",
    "        hidden_state = output_gate * tanh(cell_state_gate)\n",
    "        y = np.dot(np.transpose(w_hy), hidden_state) + bias_y\n",
    "        return input_gate, forget_gate, cell_state_gate, output_gate, hidden_state, y\n",
    "    \n",
    "    #def CTC(y):\n",
    "        \n",
    "    \n",
    "    def rnn_lstm_model_train(input_data, output_data, epochs = 10):\n",
    "        \"\"\"input_data: sorted input data, by length, in the form of spectrograms\n",
    "        output_data: output transcripts for the audio files\n",
    "        mini_batch_size: size of the mini batch\n",
    "        epochs: no. of iterations on the dataset\"\"\"\n",
    "        for epoch in epochs:\n",
    "            for iteration in number_iterations:\n",
    "                x, y, text, input_lengths, label_lengths = datagen.iterate_dev(\n",
    "                    50, sortBy_duration = True)\n",
    "                input_gate, forget_gate, cell_state_gate, output_gate, \n",
    "                    hidden_state, y = feedforward(x)\n",
    "                \n",
    "\n",
    "#return {\n",
    "#            'x': x,  # features(padded with zero) shape(minibatch-size, time-steps, feature-dimensions)\n",
    "#            'y': y,  # Flattened output labels transformed as integers\n",
    "#            'texts': texts,  # original list of texts\n",
    "#            'input-lengths': input_lengths,  # length of each input\n",
    "#            'label-lengths': label_lengths  # length of each label\n",
    "#        }\n",
    "#for i, batch in enumerate(datagen.iterate_dev(50, sortBy_duration=True)):\n",
    "#    print i\n",
    "#    print batch"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [scorpion]",
   "language": "python",
   "name": "Python [scorpion]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
